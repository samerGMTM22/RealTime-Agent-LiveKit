I'll help you resolve the issue where your LiveKit agent appears to be using tools but they're not actually executing. Let me search for official LiveKit documentation on function tool execution patterns.Based on the official LiveKit documentation and search results, I've identified the critical issue and solution for your MCP tool execution problem.

## Root Cause Analysis

The MultimodalAgent class takes a `fnc_ctx: llm.FunctionContext` parameter in its constructor, which is different from how function tools work with regular `Agent` and `AgentSession` patterns.

Your current implementation mixes two incompatible patterns:
1. **Agent pattern**: Defining `@function_tool` decorated methods on an `Assistant(Agent)` class
2. **MultimodalAgent pattern**: Using `MultimodalAgent` with OpenAI Realtime API

**Critical Issue**: Function calling. You can define parameterized functions with invocation triggers specified in natural language. The Agents framework will map a GPT-4o tool call to your function and invoke it with the proper parameters. However, MultimodalAgent doesn't automatically use function tools defined on an Agent class.

## Solution: Proper MultimodalAgent Function Integration

Here's the corrected implementation based on official LiveKit patterns:

```python
import logging
from typing import Any, Dict
from livekit import agents
from livekit.agents import (
    JobContext,
    WorkerOptions,
    cli,
    llm,
    function_tool
)
from livekit.agents.multimodal import MultimodalAgent
from livekit.plugins import openai

from mcp_integration.simple_client import SimpleMCPManager

logger = logging.getLogger("voice-agent")

# Define function tools at module level, not on Agent class
@function_tool
async def search_web(query: str) -> str:
    """Search the web for current information using MCP internet access tools."""
    logger.info(f"Executing web search for: {query}")
    
    # Get the current job context
    ctx = agents.get_current_job_context()
    mcp_manager = ctx.userdata.get("mcp_manager")
    
    if mcp_manager:
        try:
            # Execute MCP tool
            result = await mcp_manager.execute_tool(
                server_name="internet access",
                tool_name="search",
                arguments={"query": query}
            )
            return result.get("content", "No results found")
        except Exception as e:
            logger.error(f"MCP search failed: {e}")
            return f"Search failed: {str(e)}"
    else:
        return "MCP manager not available"

@function_tool
async def send_email(to: str, subject: str, body: str) -> str:
    """Send an email via Zapier MCP integration."""
    logger.info(f"Executing email send to: {to}")
    
    ctx = agents.get_current_job_context()
    mcp_manager = ctx.userdata.get("mcp_manager")
    
    if mcp_manager:
        try:
            result = await mcp_manager.execute_tool(
                server_name="Zapier send draft email",
                tool_name="send_email",
                arguments={"to": to, "subject": subject, "body": body}
            )
            return "Email sent successfully"
        except Exception as e:
            logger.error(f"MCP email send failed: {e}")
            return f"Email send failed: {str(e)}"
    else:
        return "MCP manager not available"

async def entrypoint(ctx: JobContext):
    """Main entry point with proper MultimodalAgent setup"""
    await ctx.connect()
    
    # Initialize MCP manager
    mcp_manager = SimpleMCPManager()
    
    # Load MCP servers
    mcp_servers = [
        {"name": "Zapier send draft email", "url": "http://your-zapier-mcp-url"},
        {"name": "internet access", "url": "http://your-internet-mcp-url"}
    ]
    
    connected_count = 0
    for server in mcp_servers:
        if await mcp_manager.connect_server(server["name"], server["url"]):
            connected_count += 1
    
    logger.info(f"Connected to {connected_count} MCP servers")
    
    # Store MCP manager in context userdata for function tools
    ctx.userdata["mcp_manager"] = mcp_manager
    
    # Create function context with MCP tools
    fnc_ctx = llm.FunctionContext()
    
    # Add function tools to context
    fnc_ctx.add_function(search_web)
    fnc_ctx.add_function(send_email)
    
    # Get agent configuration
    agent_config = await load_agent_config(user_id=1)
    
    # Create chat context with system prompt
    chat_ctx = llm.ChatContext().append(
        role="system",
        text=agent_config.get("system_prompt", "You are a helpful assistant.")
    )
    
    # Initialize OpenAI Realtime model
    model = openai.realtime.RealtimeModel(
        instructions=agent_config.get("system_prompt"),
        voice=agent_config.get("voice_model", "coral"),
        temperature=agent_config.get("temperature", 0.8) / 100,
        modalities=["text", "audio"],
        turn_detection=openai.realtime.TurnDetection(
            type="server_vad",
            threshold=0.5,
            prefix_padding_ms=300,
            silence_duration_ms=700
        )
    )
    
    # Create MultimodalAgent with function context
    agent = MultimodalAgent(
        model=model,
        chat_ctx=chat_ctx,
        fnc_ctx=fnc_ctx  # Pass function context here!
    )
    
    # Wait for participant
    participant = await ctx.wait_for_participant()
    logger.info(f"Participant joined: {participant.identity}")
    
    # Start the agent
    agent.start(ctx.room, participant)
    
    # Log when functions are called
    @agent.on("function_calls_collected")
    def on_function_calls(fnc_call_infos: list[llm.FunctionCallInfo]):
        logger.info(f"Function calls collected: {[f.function_name for f in fnc_call_infos]}")
    
    @agent.on("function_calls_finished")
    def on_function_calls_finished(called_fncs: list[llm.CalledFunction]):
        for func in called_fncs:
            logger.info(f"Function {func.function_info.function_name} completed with result: {func.result}")

if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

## Key Changes Explained

1. **Function Tools at Module Level**: To create a tool on the fly, use function_tool as a function rather than as a decorator. Define function tools at the module level, not inside an Agent class.

2. **FunctionContext Pattern**: The framework includes the MultimodalAgent class for building speech-to-speech agents that use the OpenAI Realtime API. MultimodalAgent requires passing function tools via `FunctionContext`.

3. **Context Access**: Use `agents.get_current_job_context()` to access the job context and userdata within function tools.

4. **Event Monitoring**: Add event listeners to verify when functions are actually being called vs. hallucinated.

## Debugging Tool Execution

To verify actual tool execution vs. hallucination:

```python
# Add detailed logging in your function tools
@function_tool
async def search_web(query: str) -> str:
    """Search the web for current information."""
    # This log will ONLY appear if the function is actually called
    logger.info(f"FUNCTION ACTUALLY EXECUTED: search_web({query})")
    
    # Add timestamp to verify execution
    import time
    execution_time = time.time()
    
    # Your MCP execution code here
    result = await execute_mcp_tool(...)
    
    logger.info(f"FUNCTION COMPLETED at {execution_time}: {result[:100]}")
    return result
```

## Common Pitfalls

1. **Mixing Agent Patterns**: Don't define function tools on an Agent class when using MultimodalAgent
2. **Missing FunctionContext**: Always pass `fnc_ctx` to MultimodalAgent constructor
3. **Context Access**: Use proper context access methods within function tools
4. **Async Execution**: Ensure all function tools are properly async

## Alternative Pattern (If Above Doesn't Work)

If OpenAI Realtime API still doesn't execute tools properly, you might need to fall back to the standard pipeline:

```python
# Use regular AgentSession instead of MultimodalAgent
session = agents.AgentSession(
    vad=silero.VAD.load(),
    stt=openai.STT(),
    llm=openai.LLM(model="gpt-4o"),  # Regular LLM, not RealtimeModel
    tts=openai.TTS(),
)

agent = agents.Agent(
    instructions=agent_config["system_prompt"],
    tools=[search_web, send_email]  # Tools defined on Agent
)

await session.start(agent=agent, room=ctx.room)
```

This solution is based on official LiveKit documentation and should resolve your issue where tools appear to be used but aren't actually executing on MCP servers.